[2026-01-26 17:24:39.899019] [INFO] Starting code mix generation...
[2026-01-26 17:24:39.904415] [INFO] Ignored: /home/runner/work/ADG/ADG/.auto_doc_cache
[2026-01-26 17:24:39.904659] [INFO] Ignored: /home/runner/work/ADG/ADG/.auto_doc_cache/code_mix.txt
[2026-01-26 17:24:39.904873] [INFO] Ignored: /home/runner/work/ADG/ADG/.auto_doc_cache/report.txt
[2026-01-26 17:24:39.905279] [INFO] Ignored: /home/runner/work/ADG/ADG/.git
[2026-01-26 17:24:39.905519] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/FETCH_HEAD
[2026-01-26 17:24:39.905746] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/HEAD
[2026-01-26 17:24:39.905968] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/config
[2026-01-26 17:24:39.906218] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/config.worktree
[2026-01-26 17:24:39.906446] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/description
[2026-01-26 17:24:39.906665] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks
[2026-01-26 17:24:39.906901] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/applypatch-msg.sample
[2026-01-26 17:24:39.907154] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/commit-msg.sample
[2026-01-26 17:24:39.907398] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/fsmonitor-watchman.sample
[2026-01-26 17:24:39.907634] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/post-update.sample
[2026-01-26 17:24:39.907870] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/pre-applypatch.sample
[2026-01-26 17:24:39.908122] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/pre-commit.sample
[2026-01-26 17:24:39.908365] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/pre-merge-commit.sample
[2026-01-26 17:24:39.908600] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/pre-push.sample
[2026-01-26 17:24:39.908835] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/pre-rebase.sample
[2026-01-26 17:24:39.909093] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/pre-receive.sample
[2026-01-26 17:24:39.909334] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/prepare-commit-msg.sample
[2026-01-26 17:24:39.909571] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/push-to-checkout.sample
[2026-01-26 17:24:39.909807] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/sendemail-validate.sample
[2026-01-26 17:24:39.910058] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/hooks/update.sample
[2026-01-26 17:24:39.910295] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/index
[2026-01-26 17:24:39.910512] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/info
[2026-01-26 17:24:39.910746] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/info/exclude
[2026-01-26 17:24:39.910964] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/logs
[2026-01-26 17:24:39.911216] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/logs/HEAD
[2026-01-26 17:24:39.911453] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/logs/refs
[2026-01-26 17:24:39.911700] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/logs/refs/heads
[2026-01-26 17:24:39.911962] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/logs/refs/heads/main
[2026-01-26 17:24:39.912232] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/logs/refs/remotes
[2026-01-26 17:24:39.912500] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/logs/refs/remotes/origin
[2026-01-26 17:24:39.912776] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/logs/refs/remotes/origin/main
[2026-01-26 17:24:39.912997] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects
[2026-01-26 17:24:39.913254] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/00
[2026-01-26 17:24:39.913509] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/00/3ed33f03ba24320be674acc37e2f484440960d
[2026-01-26 17:24:39.913744] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/02
[2026-01-26 17:24:39.913993] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/02/1c388e953c4661dc3838cf999026c1f029c38b
[2026-01-26 17:24:39.914249] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/08
[2026-01-26 17:24:39.914514] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/08/3bb9598f2f3dee44e7b6d3358c592538e0c708
[2026-01-26 17:24:39.914762] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/14
[2026-01-26 17:24:39.915012] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/14/3816379e9cc4229eaaf3cdddad6a5ab36c4627
[2026-01-26 17:24:39.915266] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/16
[2026-01-26 17:24:39.915522] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/16/c6bd78d24630228f2f308279feee5992b421d5
[2026-01-26 17:24:39.915755] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/1c
[2026-01-26 17:24:39.916003] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/1c/20a24b70b74067317afc6434e5c0c301d10144
[2026-01-26 17:24:39.916258] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/23
[2026-01-26 17:24:39.916512] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/23/197aac186f300bb2c21c3ef3e906c84bed9507
[2026-01-26 17:24:39.916743] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/26
[2026-01-26 17:24:39.916991] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/26/232583984feff25da44d47972f553bd00e4daa
[2026-01-26 17:24:39.917254] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/45
[2026-01-26 17:24:39.917508] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/45/c8c97b68d9edc9608f17662ae5a56937db4722
[2026-01-26 17:24:39.917750] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/48
[2026-01-26 17:24:39.917999] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/48/2d00127da59187ea3cfc62e26186a5fe439b78
[2026-01-26 17:24:39.918249] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/4b
[2026-01-26 17:24:39.918504] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/4b/32baa38008b02ec95b5594fc51525e70ea533a
[2026-01-26 17:24:39.918734] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/4d
[2026-01-26 17:24:39.918979] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/4d/887c5d0ba32a7517cce5fc00b7935bfd365b6e
[2026-01-26 17:24:39.919228] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/50
[2026-01-26 17:24:39.919483] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/50/9b8c9fc4e905fe2754b074ecd464f204991739
[2026-01-26 17:24:39.919730] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/50/de1f7cf4fe170128039ffa6d0cc6f3f6d6cc33
[2026-01-26 17:24:39.919962] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/62
[2026-01-26 17:24:39.920231] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/62/18e73336f4ccb562643cd4202a628d14cf784f
[2026-01-26 17:24:39.920467] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/69
[2026-01-26 17:24:39.920713] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/69/d396a65001f587ed762008c81601f789adc34e
[2026-01-26 17:24:39.920943] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/6a
[2026-01-26 17:24:39.921208] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/6a/2dd502eb649bb8e804238af60031db553c13ea
[2026-01-26 17:24:39.921462] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/6a/4ee663203935f06c6f32d4d056257d4f4478a7
[2026-01-26 17:24:39.921691] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/6f
[2026-01-26 17:24:39.921941] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/6f/130bfccfc73d6fe93fe33cd3772d640379f909
[2026-01-26 17:24:39.922189] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/77
[2026-01-26 17:24:39.922442] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/77/4f95ed2142b9dc1709dc3dcce5f35519240464
[2026-01-26 17:24:39.922674] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/7e
[2026-01-26 17:24:39.922922] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/7e/f15dd6d3c3dd489f000b4267a54b0d72c0d559
[2026-01-26 17:24:39.923182] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/81
[2026-01-26 17:24:39.923436] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/81/becbf7a8a1c3473195d0f85266ab25f85809ce
[2026-01-26 17:24:39.923672] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/84
[2026-01-26 17:24:39.923918] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/84/00c2b5c8734df41836d301824574b989b0ec41
[2026-01-26 17:24:39.924167] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/88
[2026-01-26 17:24:39.924430] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/88/0d58d664412fbc1fd1ab273ef396daf3699102
[2026-01-26 17:24:39.924661] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/8a
[2026-01-26 17:24:39.924918] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/8a/b47c5bc8110cef05224baba95761fd822aa22a
[2026-01-26 17:24:39.925204] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/94
[2026-01-26 17:24:39.925466] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/94/e480e5d5e7e16b2be7889ae9e81f561e9bdb50
[2026-01-26 17:24:39.925699] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/a5
[2026-01-26 17:24:39.925947] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/a5/5db6b773130ad03a6a78925677a1c6015fa85b
[2026-01-26 17:24:39.926206] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/a8
[2026-01-26 17:24:39.926461] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/a8/476127e3f807c0aa99fa808560ec2e5584dff2
[2026-01-26 17:24:39.926692] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/b6
[2026-01-26 17:24:39.926940] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/b6/d812aceb9c792cb2019b9e244e1dbaa4ad74a1
[2026-01-26 17:24:39.927190] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/bc
[2026-01-26 17:24:39.927444] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/bc/a8064adcc1252a4fbd8efe7a3e7705aad9db97
[2026-01-26 17:24:39.927676] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/c0
[2026-01-26 17:24:39.927922] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/c0/224d10f6c6beabb97a1deca15605170948edad
[2026-01-26 17:24:39.928170] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/ca
[2026-01-26 17:24:39.928424] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/ca/3f28b6a4a95a7176cdf2d78622ceb1151e186d
[2026-01-26 17:24:39.928655] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/cf
[2026-01-26 17:24:39.928901] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/cf/bdcdf27d06f2404277a03319ef0e13e5811798
[2026-01-26 17:24:39.929226] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/d6
[2026-01-26 17:24:39.929498] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/d6/54eaa4d6edf57be77d54c32c20a0ccb843373f
[2026-01-26 17:24:39.929733] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/d9
[2026-01-26 17:24:39.929983] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/d9/c5e7426b4d3d800f9cca0b469d6f0c60fe27b7
[2026-01-26 17:24:39.930266] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/db
[2026-01-26 17:24:39.930526] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/db/80ec4419abf97b42fd51f286a6dd599d8d77ce
[2026-01-26 17:24:39.930759] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/e6
[2026-01-26 17:24:39.931006] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/e6/6a9a3619184fb9947c0d24768a8ba31246f1f0
[2026-01-26 17:24:39.931295] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/e6/9de29bb2d1d6434b8b29ae775ad8c2e48c5391
[2026-01-26 17:24:39.931533] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/e7
[2026-01-26 17:24:39.931782] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/e7/746f47e059234c8b861cf312d97132a810e145
[2026-01-26 17:24:39.932015] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/ef
[2026-01-26 17:24:39.932285] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/ef/9fb37763d620555f3e448337bcdb1ac580b349
[2026-01-26 17:24:39.932524] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/fb
[2026-01-26 17:24:39.932776] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/fb/8b56ad03d86c61f46cb2c93a162215b23ce129
[2026-01-26 17:24:39.933011] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/fd
[2026-01-26 17:24:39.933290] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/fd/e71a3921784193a3be16833a366cce84f85993
[2026-01-26 17:24:39.933530] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/ff
[2026-01-26 17:24:39.933784] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/ff/963568ede49b719e07b95fb29b788c5ac26940
[2026-01-26 17:24:39.934077] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/ff/f080b973d3aee3c8f7fa07952369740b4105fe
[2026-01-26 17:24:39.934328] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/info
[2026-01-26 17:24:39.934564] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/objects/pack
[2026-01-26 17:24:39.934783] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/refs
[2026-01-26 17:24:39.935015] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/refs/heads
[2026-01-26 17:24:39.935285] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/refs/heads/main
[2026-01-26 17:24:39.935523] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/refs/remotes
[2026-01-26 17:24:39.935771] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/refs/remotes/origin
[2026-01-26 17:24:39.936048] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/refs/remotes/origin/main
[2026-01-26 17:24:39.936297] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/refs/tags
[2026-01-26 17:24:39.936522] [INFO] Ignored: /home/runner/work/ADG/ADG/.git/shallow
[2026-01-26 17:24:39.938789] [INFO] Ignored: /home/runner/work/ADG/ADG/.gitignore
[2026-01-26 17:24:39.939043] [INFO] Ignored: /home/runner/work/ADG/ADG/README.md
[2026-01-26 17:24:39.940103] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/__pycache__
[2026-01-26 17:24:39.940335] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/__pycache__/__init__.cpython-312.pyc
[2026-01-26 17:24:39.940557] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/__pycache__/manage.cpython-312.pyc
[2026-01-26 17:24:39.941106] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/auto_runner/__pycache__
[2026-01-26 17:24:39.941352] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/auto_runner/__pycache__/config_reader.cpython-312.pyc
[2026-01-26 17:24:39.941590] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/auto_runner/__pycache__/run_file.cpython-312.pyc
[2026-01-26 17:24:39.943123] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/engine/__pycache__
[2026-01-26 17:24:39.943371] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/engine/__pycache__/__init__.cpython-312.pyc
[2026-01-26 17:24:39.943605] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/engine/__pycache__/exceptions.cpython-312.pyc
[2026-01-26 17:24:39.944176] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/engine/config/__pycache__
[2026-01-26 17:24:39.944442] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/engine/config/__pycache__/config.cpython-312.pyc
[2026-01-26 17:24:39.945683] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/engine/models/__pycache__
[2026-01-26 17:24:39.945941] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/engine/models/__pycache__/gpt_model.cpython-312.pyc
[2026-01-26 17:24:39.946233] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/engine/models/__pycache__/model.cpython-312.pyc
[2026-01-26 17:24:39.947762] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/factory/__pycache__
[2026-01-26 17:24:39.948005] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/factory/__pycache__/__init__.cpython-312.pyc
[2026-01-26 17:24:39.948260] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/factory/__pycache__/base_factory.cpython-312.pyc
[2026-01-26 17:24:39.949173] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/factory/modules/__pycache__
[2026-01-26 17:24:39.949436] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/factory/modules/__pycache__/general_modules.cpython-312.pyc
[2026-01-26 17:24:39.949687] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/factory/modules/__pycache__/intro.cpython-312.pyc
[2026-01-26 17:24:39.951214] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/postprocessor/__pycache__
[2026-01-26 17:24:39.951458] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/postprocessor/__pycache__/custom_intro.cpython-312.pyc
[2026-01-26 17:24:39.951692] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/postprocessor/__pycache__/sorting.cpython-312.pyc
[2026-01-26 17:24:39.952855] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/preprocessor/__pycache__
[2026-01-26 17:24:39.953132] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/preprocessor/__pycache__/code_mix.cpython-312.pyc
[2026-01-26 17:24:39.953374] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/preprocessor/__pycache__/compressor.cpython-312.pyc
[2026-01-26 17:24:39.953610] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/preprocessor/__pycache__/settings.cpython-312.pyc
[2026-01-26 17:24:39.953844] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/preprocessor/__pycache__/spliter.cpython-312.pyc
[2026-01-26 17:24:39.955963] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/ui/__pycache__
[2026-01-26 17:24:39.956230] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/ui/__pycache__/__init__.cpython-312.pyc
[2026-01-26 17:24:39.956471] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/ui/__pycache__/logging.cpython-312.pyc
[2026-01-26 17:24:39.956705] [INFO] Ignored: /home/runner/work/ADG/ADG/autodocgenerator/ui/__pycache__/progress_base.cpython-312.pyc
[2026-01-26 17:24:39.995337] [INFO] Code mix generation completed.
[2026-01-26 17:24:39.996794] [INFO] Starting synchronous documentation generation by parts...
[2026-01-26 17:24:39.997083] [INFO] Starting data splitting...
[2026-01-26 17:24:39.997166] [INFO] Data split into 6 parts based on max symbols 10000.
[2026-01-26 17:24:39.997194] [INFO] Starting documentation generation by parts...
[2026-01-26 17:24:39.997236] [INFO] Generating documentation for a part...
[2026-01-26 17:24:39.997282] [INFO] Generating answer...
[2026-01-26 17:24:41.759408] [INFO] Generated answer with model openai/gpt-oss-120b.
[2026-01-26 17:24:41.759476] [INFO] Answer: <a name="configuration-loading"></a>
## Configuration Loading & Factory Preparation  
`read_config` parses **autodocconfig.yml**, builds a `Config` object, and populates: language, ignore patterns, `ProjectConfigSettings`, additional info, and a list of `CustomModule` instances. It then returns two factories – a generic `doc_factory` (custom modules) and an `intro_factory` (static intro components).

<a name="model-initialization"></a>
## GPT Model Instantiation  
```python
sync_model = GPTModel(API_KEY, use_random=False)
async_model = AsyncGPTModel(API_KEY)
```  
Both models receive the API key from `engine.config`. The synchronous model is used for deterministic calls, while the async variant is prepared for future parallelism.

<a name="manager-orchestration"></a>
## Manager Orchestration & Generation Steps  
A `Manager` is created with the project root, `ProjectSettings`, `ProjectConfigSettings`, the ignore list, and a `ConsoleGtiHubProgress` bar. The subsequent calls execute the full pipeline:  

1. `generate_code_file()` – extracts source files.  
2. `generate_global_info_file(use_async=False, max_symbols=8000)` – builds a project‑wide summary.  
3. `generete_doc_parts(use_async=False, max_symbols=10000)` – splits code into doc‑ready chunks.  
4. `factory_generate_doc(doc_factory)` – runs user‑defined modules.  
5. `order_doc()` – sorts sections.  
6. `factory_generate_doc(intro_factory)` – prepends introductory material.  

Finally, `clear_cache()` removes temporary artifacts and `read_file_by_file_key("output_doc")` returns the rendered Markdown.

<a name="execution-flow"></a>
## Script Execution Flow  
When invoked as a module, the script reads *autodocconfig.yml*, resolves factories, calls `gen_doc` with the assembled parameters, and stores the result in `output_doc`. All side effects (file generation, cache cleanup, progress rendering) are confined to the `Manager` instance.
[2026-01-26 17:24:41.759521] [INFO] Documentation for part generated. total length: 1918
[2026-01-26 17:24:41.759545] [INFO] Part Documentation: <a name="configuration-loading"></a>
## Configuration Loading & Factory Preparation  
`read_config` parses **autodocconfig.yml**, builds a `Config` object, and populates: language, ignore patterns, `ProjectConfigSettings`, additional info, and a list of `CustomModule` instances. It then returns two factories – a generic `doc_factory` (custom modules) and an `intro_factory` (static intro components).

<a name="model-initialization"></a>
## GPT Model Instantiation  
```python
sync_model = GPTModel(API_KEY, use_random=False)
async_model = AsyncGPTModel(API_KEY)
```  
Both models receive the API key from `engine.config`. The synchronous model is used for deterministic calls, while the async variant is prepared for future parallelism.

<a name="manager-orchestration"></a>
## Manager Orchestration & Generation Steps  
A `Manager` is created with the project root, `ProjectSettings`, `ProjectConfigSettings`, the ignore list, and a `ConsoleGtiHubProgress` bar. The subsequent calls execute the full pipeline:  

1. `generate_code_file()` – extracts source files.  
2. `generate_global_info_file(use_async=False, max_symbols=8000)` – builds a project‑wide summary.  
3. `generete_doc_parts(use_async=False, max_symbols=10000)` – splits code into doc‑ready chunks.  
4. `factory_generate_doc(doc_factory)` – runs user‑defined modules.  
5. `order_doc()` – sorts sections.  
6. `factory_generate_doc(intro_factory)` – prepends introductory material.  

Finally, `clear_cache()` removes temporary artifacts and `read_file_by_file_key("output_doc")` returns the rendered Markdown.

<a name="execution-flow"></a>
## Script Execution Flow  
When invoked as a module, the script reads *autodocconfig.yml*, resolves factories, calls `gen_doc` with the assembled parameters, and stores the result in `output_doc`. All side effects (file generation, cache cleanup, progress rendering) are confined to the `Manager` instance.
[2026-01-26 17:24:41.759623] [INFO] Generating documentation for a part...
[2026-01-26 17:24:41.759653] [INFO] Generating answer...
[2026-01-26 17:24:43.536786] [INFO] Generated answer with model openai/gpt-oss-120b.
[2026-01-26 17:24:43.536846] [INFO] Answer: <a name="model-generation-responsibility"></a>
## Model Generation Responsibility
Implements concrete `GPTModel` (sync) and `AsyncGPTModel` (async) subclasses of the engine’s abstract `Model`/`AsyncModel`. Each class wraps a Groq client, selects a viable model from `regen_models_name`, and returns the generated text while logging progress.

<a name="model-interactions"></a>
## Interaction with Engine & UI
- Inherits shared state (`api_key`, `history`, `use_random`, `regen_models_name`, `current_model_index`) from the base classes.  
- Uses `BaseLogger` from `ui.logging` to emit `InfoLog`, `WarningLog`, and `ErrorLog`.  
- Raises `ModelExhaustedException` when no model remains usable, propagating the error to the surrounding `Manager` workflow.

<a name="model-technical-details"></a>
## Technical Details
- **`__init__`**: Instantiates `Groq` or `AsyncGroq` client with the supplied API key; sets up a logger.  
- **`generate_answer` / `async generate_answer`**:  
  1. Determines message payload (`history.history` vs. direct `prompt`).  
  2. Enters a loop selecting `model_name` from `regen_models_name`.  
  3. Calls `client.chat.completions.create`.  
  4. On exception, logs a warning and advances `current_model_index` (wrap‑around).  
  5. Upon success, extracts `content` from `chat_completion.choices[0].message`.  
  6. Logs the chosen model and final answer before returning it.

<a name="model-data-flow"></a>
## Data Flow & Side Effects
- **Inputs**: `api_key`, optional `history` object, `use_random` flag, `with_history` boolean, optional `prompt` string.  
- **Outputs**: Generated answer string.  
- **Side Effects**: Logging activity, possible modification of `current_model_index`, and raising `ModelExhaustedException` when the model pool is empty.  
- **Assumptions**: `regen_models_name` is pre‑populated with viable model identifiers; `History` provides a `history` list compatible with Groq’s chat API.
[2026-01-26 17:24:43.536882] [INFO] Documentation for part generated. total length: 1937
[2026-01-26 17:24:43.536917] [INFO] Part Documentation: <a name="model-generation-responsibility"></a>
## Model Generation Responsibility
Implements concrete `GPTModel` (sync) and `AsyncGPTModel` (async) subclasses of the engine’s abstract `Model`/`AsyncModel`. Each class wraps a Groq client, selects a viable model from `regen_models_name`, and returns the generated text while logging progress.

<a name="model-interactions"></a>
## Interaction with Engine & UI
- Inherits shared state (`api_key`, `history`, `use_random`, `regen_models_name`, `current_model_index`) from the base classes.  
- Uses `BaseLogger` from `ui.logging` to emit `InfoLog`, `WarningLog`, and `ErrorLog`.  
- Raises `ModelExhaustedException` when no model remains usable, propagating the error to the surrounding `Manager` workflow.

<a name="model-technical-details"></a>
## Technical Details
- **`__init__`**: Instantiates `Groq` or `AsyncGroq` client with the supplied API key; sets up a logger.  
- **`generate_answer` / `async generate_answer`**:  
  1. Determines message payload (`history.history` vs. direct `prompt`).  
  2. Enters a loop selecting `model_name` from `regen_models_name`.  
  3. Calls `client.chat.completions.create`.  
  4. On exception, logs a warning and advances `current_model_index` (wrap‑around).  
  5. Upon success, extracts `content` from `chat_completion.choices[0].message`.  
  6. Logs the chosen model and final answer before returning it.

<a name="model-data-flow"></a>
## Data Flow & Side Effects
- **Inputs**: `api_key`, optional `history` object, `use_random` flag, `with_history` boolean, optional `prompt` string.  
- **Outputs**: Generated answer string.  
- **Side Effects**: Logging activity, possible modification of `current_model_index`, and raising `ModelExhaustedException` when the model pool is empty.  
- **Assumptions**: `regen_models_name` is pre‑populated with viable model identifiers; `History` provides a `history` list compatible with Groq’s chat API.
[2026-01-26 17:24:43.536986] [INFO] Generating documentation for a part...
[2026-01-26 17:24:43.537015] [INFO] Generating answer...
[2026-01-26 17:24:56.495848] [INFO] Generated answer with model openai/gpt-oss-120b.
[2026-01-26 17:24:56.495908] [INFO] Answer: <a name="history-management"></a>
## History Management  

The `History` class records conversation turns for chat‑style LLM calls.  
- **Constructor** (`__init__(system_prompt)`) creates an empty `history` list and, if a system prompt is supplied, inserts a `"system"` role entry.  
- **add_to_history(role, content)** appends a dict `{"role": role, "content": content}` to `self.history`.  
*Assumption*: callers provide plain strings; the list format matches Groq/Chat‑ML expectations.

<a name="parentmodel-initialization"></a>
## ParentModel Initialization  

`ParentModel` supplies shared state for both sync and async models.  
- Accepts `api_key` (default from config), a `History` instance, and `use_random`.  
- Stores `self.history`, `self.api_key`, and starts `self.current_model_index = 0`.  
- Copies `MODELS_NAME`, shuffles it when `use_random=True`, and exposes the ordered list as `self.regen_models_name`.  
*Side effect*: randomisation of model selection order for subsequent calls to `generate_answer`.

<a name="synchronous-model-interface"></a>
## Synchronous Model Interface  

`Model` inherits from `ParentModel` and implements three thin wrappers around `generate_answer`.  
- `generate_answer(with_history=True, prompt=None) -> str` – placeholder returning `"answer"` (real implementation is injected elsewhere).  
- `get_answer_without_history(prompt)` forwards to `generate_answer(with_history=False, ...)`.  
- `get_answer(prompt)` records the user prompt, calls `generate_answer()`, stores the assistant reply, and returns the answer.  
*Data flow*: `prompt` → history → `generate_answer` → answer → history.

<a name="asynchronous-model-interface"></a>
## Asynchronous Model Interface  

`AsyncModel` mirrors `Model` but with `async` methods.  
- `async generate_answer(with_history=True, prompt=None) -> str` – stub returning `"answer"`.  
- `async get_answer_without_history(prompt)` awaits `generate_answer`.  
- `async get_answer(prompt)` updates history synchronously, then awaits `generate_answer` before storing and returning the result.  

Both interfaces rely on the shared `History` instance and respect the ordered `regen_models_name` list for model selection in the real `generate_answer` implementation.
[2026-01-26 17:24:56.495954] [INFO] Documentation for part generated. total length: 2247
[2026-01-26 17:24:56.495977] [INFO] Part Documentation: <a name="history-management"></a>
## History Management  

The `History` class records conversation turns for chat‑style LLM calls.  
- **Constructor** (`__init__(system_prompt)`) creates an empty `history` list and, if a system prompt is supplied, inserts a `"system"` role entry.  
- **add_to_history(role, content)** appends a dict `{"role": role, "content": content}` to `self.history`.  
*Assumption*: callers provide plain strings; the list format matches Groq/Chat‑ML expectations.

<a name="parentmodel-initialization"></a>
## ParentModel Initialization  

`ParentModel` supplies shared state for both sync and async models.  
- Accepts `api_key` (default from config), a `History` instance, and `use_random`.  
- Stores `self.history`, `self.api_key`, and starts `self.current_model_index = 0`.  
- Copies `MODELS_NAME`, shuffles it when `use_random=True`, and exposes the ordered list as `self.regen_models_name`.  
*Side effect*: randomisation of model selection order for subsequent calls to `generate_answer`.

<a name="synchronous-model-interface"></a>
## Synchronous Model Interface  

`Model` inherits from `ParentModel` and implements three thin wrappers around `generate_answer`.  
- `generate_answer(with_history=True, prompt=None) -> str` – placeholder returning `"answer"` (real implementation is injected elsewhere).  
- `get_answer_without_history(prompt)` forwards to `generate_answer(with_history=False, ...)`.  
- `get_answer(prompt)` records the user prompt, calls `generate_answer()`, stores the assistant reply, and returns the answer.  
*Data flow*: `prompt` → history → `generate_answer` → answer → history.

<a name="asynchronous-model-interface"></a>
## Asynchronous Model Interface  

`AsyncModel` mirrors `Model` but with `async` methods.  
- `async generate_answer(with_history=True, prompt=None) -> str` – stub returning `"answer"`.  
- `async get_answer_without_history(prompt)` awaits `generate_answer`.  
- `async get_answer(prompt)` updates history synchronously, then awaits `generate_answer` before storing and returning the result.  

Both interfaces rely on the shared `History` instance and respect the ordered `regen_models_name` list for model selection in the real `generate_answer` implementation.
[2026-01-26 17:24:56.496059] [INFO] Generating documentation for a part...
[2026-01-26 17:24:56.496102] [INFO] Generating answer...
[2026-01-26 17:25:19.867150] [INFO] Generated answer with model openai/gpt-oss-120b.
[2026-01-26 17:25:19.867213] [INFO] Answer: <a name="html-link-extractor"></a>
## HTML Link Extractor  

**Responsibility** – Scans a documentation string for `<a name="…"></a>` anchors and returns a list of Markdown‑style fragment links (`#anchor`).  

**Interactions** – Called by the post‑processing pipeline to build a navigation index; relies only on Python’s `re` module and the internal `BaseLogger`.  

**Technical details** –  
- Compiles a simple regex `r'<a name=["\']?(.*?)["\']?>'`.  
- Iterates `re.finditer`, extracts the captured group, prefixes with `#`, logs progress and result.  

**Data flow** – Input: raw HTML/markdown `data : str` → regex search → `links : list[str]` → returned to caller; side effect: logger writes two `InfoLog` entries.

---

<a name="link-introduction-generator"></a>
## Link Introduction Generator  

**Responsibility** – Generates a natural‑language intro that references a set of extracted links.  

**Interactions** – Uses a `Model` implementation (e.g., `GPTModel`) to call `model.get_answer_without_history`. The prompt combines a language directive, a constant `BASE_INTRODACTION_CREATE_TEXT`, and the stringified link list.  

**Technical details** –  
- Builds a 3‑message system/user prompt.  
- Logs before/after the LLM call.  
- Returns the LLM‑produced `intro_links : str`.  

**Data flow** – `links → prompt → model.get_answer_without_history → intro_links`; side effect: three log entries.

---

<a name="global-introduction-generator"></a>
## Global Introduction Generator  

**Responsibility** – Produces a full introductory paragraph for the whole documentation block.  

**Interactions** – Similar to the link generator but uses `BASE_INTRO_CREATE` as the system prompt and passes the complete `global_data`.  

**Technical details** – Constructs a 3‑message prompt and returns the model’s answer unchanged.  

**Data flow** – `global_data → prompt → model.get_answer_without_history → intro`.

---

<a name="custom-description-engine"></a>
## Custom Description Engine  

**Responsibility** – Iterates over split documentation chunks, asking the LLM to create concise, anchor‑prefixed descriptions for a user‑supplied `custom_description`.  

**Interactions** – For each chunk it sends a detailed system prompt (language, role, strict rules) plus a user task to the same `Model`. Stops on the first non‑empty, non‑`!noinfo` result.  

**Technical details** –  
- Loops over `splited_data`.  
- Uses strict rule block to enforce empty output when info is missing.  
- Breaks when a valid result appears; otherwise returns an empty string.  

**Data flow** – `splited_data + custom_description → per‑chunk prompt → model.get_answer_without_history → result`.

---

<a name="anchor-based-chunk-splitter"></a>
## Anchor‑Based Chunk Splitter & Sorter  

**Responsibility** – Parses a monolithic HTML/markdown document into anchor‑delimited chunks, validates one‑to‑one anchor‑chunk mapping, and orders chunks semantically via LLM.  

**Interactions** – `extract_links_from_start` and `split_text_by_anchors` produce a dict `{anchor: chunk}`. `get_order` sends the list of titles to the `Model` for sorting, then reassembles the ordered text.  

**Technical details** –  
- Regex `^<a name=…>` extracts leading anchors.  
- `re.split` with look‑ahead splits on anchor boundaries.  
- Validation: `len(all_links) == len(chunks)` else `None`.  
- Prompt for sorting: single‑message user request, expects comma‑separated titles.  
- Reassembles via `order_output += f"{chanks.get(el)} \n"`.  

**Data flow** – `text → split_text_by_anchors → dict` → `get_order(dict) → sorted string`; logs each step.

---

<a name="repository-content-packager"></a>
## Repository Content Packager  

**Responsibility** – Traverses a project directory, writes a hierarchical tree view and in‑line file contents to a single output file (`repomix-output.txt`).  

**Interactions** – Uses `Path.rglob` to enumerate files, `should_ignore` to filter based on `ignore_patterns`, and `BaseLogger` for progress logs. No external services.  

**Technical details** –  
- `should_ignore` matches against glob patterns, file basenames, and any path component.  
- `build_repo_content` writes a “Repository Structure” block, then each non‑ignored file wrapped in `<file path="…">` tags.  
- Handles read errors with a catch‑all exception, inserting an error line.  

**Data flow** – `root_dir + ignore_patterns → file enumeration → filtered list → output file` (side effect: file creation + log entries).
[2026-01-26 17:25:19.867269] [INFO] Documentation for part generated. total length: 4488
[2026-01-26 17:25:19.867294] [INFO] Part Documentation: <a name="html-link-extractor"></a>
## HTML Link Extractor  

**Responsibility** – Scans a documentation string for `<a name="…"></a>` anchors and returns a list of Markdown‑style fragment links (`#anchor`).  

**Interactions** – Called by the post‑processing pipeline to build a navigation index; relies only on Python’s `re` module and the internal `BaseLogger`.  

**Technical details** –  
- Compiles a simple regex `r'<a name=["\']?(.*?)["\']?>'`.  
- Iterates `re.finditer`, extracts the captured group, prefixes with `#`, logs progress and result.  

**Data flow** – Input: raw HTML/markdown `data : str` → regex search → `links : list[str]` → returned to caller; side effect: logger writes two `InfoLog` entries.

---

<a name="link-introduction-generator"></a>
## Link Introduction Generator  

**Responsibility** – Generates a natural‑language intro that references a set of extracted links.  

**Interactions** – Uses a `Model` implementation (e.g., `GPTModel`) to call `model.get_answer_without_history`. The prompt combines a language directive, a constant `BASE_INTRODACTION_CREATE_TEXT`, and the stringified link list.  

**Technical details** –  
- Builds a 3‑message system/user prompt.  
- Logs before/after the LLM call.  
- Returns the LLM‑produced `intro_links : str`.  

**Data flow** – `links → prompt → model.get_answer_without_history → intro_links`; side effect: three log entries.

---

<a name="global-introduction-generator"></a>
## Global Introduction Generator  

**Responsibility** – Produces a full introductory paragraph for the whole documentation block.  

**Interactions** – Similar to the link generator but uses `BASE_INTRO_CREATE` as the system prompt and passes the complete `global_data`.  

**Technical details** – Constructs a 3‑message prompt and returns the model’s answer unchanged.  

**Data flow** – `global_data → prompt → model.get_answer_without_history → intro`.

---

<a name="custom-description-engine"></a>
## Custom Description Engine  

**Responsibility** – Iterates over split documentation chunks, asking the LLM to create concise, anchor‑prefixed descriptions for a user‑supplied `custom_description`.  

**Interactions** – For each chunk it sends a detailed system prompt (language, role, strict rules) plus a user task to the same `Model`. Stops on the first non‑empty, non‑`!noinfo` result.  

**Technical details** –  
- Loops over `splited_data`.  
- Uses strict rule block to enforce empty output when info is missing.  
- Breaks when a valid result appears; otherwise returns an empty string.  

**Data flow** – `splited_data + custom_description → per‑chunk prompt → model.get_answer_without_history → result`.

---

<a name="anchor-based-chunk-splitter"></a>
## Anchor‑Based Chunk Splitter & Sorter  

**Responsibility** – Parses a monolithic HTML/markdown document into anchor‑delimited chunks, validates one‑to‑one anchor‑chunk mapping, and orders chunks semantically via LLM.  

**Interactions** – `extract_links_from_start` and `split_text_by_anchors` produce a dict `{anchor: chunk}`. `get_order` sends the list of titles to the `Model` for sorting, then reassembles the ordered text.  

**Technical details** –  
- Regex `^<a name=…>` extracts leading anchors.  
- `re.split` with look‑ahead splits on anchor boundaries.  
- Validation: `len(all_links) == len(chunks)` else `None`.  
- Prompt for sorting: single‑message user request, expects comma‑separated titles.  
- Reassembles via `order_output += f"{chanks.get(el)} \n"`.  

**Data flow** – `text → split_text_by_anchors → dict` → `get_order(dict) → sorted string`; logs each step.

---

<a name="repository-content-packager"></a>
## Repository Content Packager  

**Responsibility** – Traverses a project directory, writes a hierarchical tree view and in‑line file contents to a single output file (`repomix-output.txt`).  

**Interactions** – Uses `Path.rglob` to enumerate files, `should_ignore` to filter based on `ignore_patterns`, and `BaseLogger` for progress logs. No external services.  

**Technical details** –  
- `should_ignore` matches against glob patterns, file basenames, and any path component.  
- `build_repo_content` writes a “Repository Structure” block, then each non‑ignored file wrapped in `<file path="…">` tags.  
- Handles read errors with a catch‑all exception, inserting an error line.  

**Data flow** – `root_dir + ignore_patterns → file enumeration → filtered list → output file` (side effect: file creation + log entries).
[2026-01-26 17:25:19.867367] [INFO] Generating documentation for a part...
[2026-01-26 17:25:19.867396] [INFO] Generating answer...
[2026-01-26 17:25:50.456329] [INFO] Generated answer with model openai/gpt-oss-120b.
[2026-01-26 17:25:50.456394] [INFO] Answer: <a name="compression-engine"></a>
## Compression Engine  

**Responsibility** – Reduces raw text (code or docs) to a concise form using the LLM, optionally grouping several inputs into a single compressed block for later comparison.  

**Interactions** – Calls `project_settings.prompt` and `get_BASE_COMPRESS_TEXT` to build a three‑message prompt, then invokes `model.get_answer_without_history`.  Progress is reported via a `BaseProgress` instance.  

**Technical details** –  
- `compress` builds the prompt (`system` → project prompt, `system` → compress‑text template, `user` → data).  
- `compress_and_compare` iterates over a list, concatenating every *compress_power* results; updates the progress bar.  
- Async counterparts (`async_compress`, `async_compress_and_compare`) run under a semaphore and use `await model.get_answer_without_history`.  

**Data flow** – `data (+ settings) → prompt → model → compressed string`; aggregated list → progress bar side‑effects.

<a name="project-settings-builder"></a>
## Project Settings Builder  

**Responsibility** – Generates a dynamic system prompt containing base settings and project‑specific key/value pairs.  

**Interactions** – Consumed by the compressor and splitter when they need a contextual system message.  

**Technical details** –  
- `ProjectSettings` stores `project_name` and an `info` dict.  
- `add_info(key, value)` mutates the dict.  
- The `prompt` property concatenates `BASE_SETTINGS_PROMPT`, the project name, and each `info` entry on separate lines.  

**Data flow** – `ProjectSettings` instance → `prompt` string → injected into LLM prompts.

<a name="chunk-splitter-and-doc-generator"></a>
## Chunk Splitter & Documentation Generator  

**Responsibility** – Splits a large monolithic source string into size‑constrained chunks, then drives LLM‑based documentation generation per chunk (sync or async).  

**Interactions** – Uses `BASE_PART_COMPLITE_TEXT` as a system prompt, optionally carries forward previous part output (`prev_info`).  Logs via `BaseLogger` and reports progress with `BaseProgress`.  

**Technical details** –  
- `split_data` respects `max_symbols`, recursively breaks overly long lines, and packs them into a list of chunks.  
- `write_docs_by_parts` builds a prompt (system language/id, system base text, optional previous info, user chunk) and cleans surrounding markdown fences.  
- Async versions (`async_write_docs_by_parts`, `async_gen_doc_parts`) run under a semaphore and update progress via a callback.  
- `gen_doc_parts`/`async_gen_doc_parts` orchestrate chunk processing, concatenate results, and keep a trailing context slice (≈ 3000 chars).  

**Data flow** – `full_code_mix → split_data → [chunks] → per‑chunk prompt → model → documentation string → aggregated output (side‑effect: logs & progress updates).
[2026-01-26 17:25:50.456432] [INFO] Documentation for part generated. total length: 2827
[2026-01-26 17:25:50.456458] [INFO] Part Documentation: <a name="compression-engine"></a>
## Compression Engine  

**Responsibility** – Reduces raw text (code or docs) to a concise form using the LLM, optionally grouping several inputs into a single compressed block for later comparison.  

**Interactions** – Calls `project_settings.prompt` and `get_BASE_COMPRESS_TEXT` to build a three‑message prompt, then invokes `model.get_answer_without_history`.  Progress is reported via a `BaseProgress` instance.  

**Technical details** –  
- `compress` builds the prompt (`system` → project prompt, `system` → compress‑text template, `user` → data).  
- `compress_and_compare` iterates over a list, concatenating every *compress_power* results; updates the progress bar.  
- Async counterparts (`async_compress`, `async_compress_and_compare`) run under a semaphore and use `await model.get_answer_without_history`.  

**Data flow** – `data (+ settings) → prompt → model → compressed string`; aggregated list → progress bar side‑effects.

<a name="project-settings-builder"></a>
## Project Settings Builder  

**Responsibility** – Generates a dynamic system prompt containing base settings and project‑specific key/value pairs.  

**Interactions** – Consumed by the compressor and splitter when they need a contextual system message.  

**Technical details** –  
- `ProjectSettings` stores `project_name` and an `info` dict.  
- `add_info(key, value)` mutates the dict.  
- The `prompt` property concatenates `BASE_SETTINGS_PROMPT`, the project name, and each `info` entry on separate lines.  

**Data flow** – `ProjectSettings` instance → `prompt` string → injected into LLM prompts.

<a name="chunk-splitter-and-doc-generator"></a>
## Chunk Splitter & Documentation Generator  

**Responsibility** – Splits a large monolithic source string into size‑constrained chunks, then drives LLM‑based documentation generation per chunk (sync or async).  

**Interactions** – Uses `BASE_PART_COMPLITE_TEXT` as a system prompt, optionally carries forward previous part output (`prev_info`).  Logs via `BaseLogger` and reports progress with `BaseProgress`.  

**Technical details** –  
- `split_data` respects `max_symbols`, recursively breaks overly long lines, and packs them into a list of chunks.  
- `write_docs_by_parts` builds a prompt (system language/id, system base text, optional previous info, user chunk) and cleans surrounding markdown fences.  
- Async versions (`async_write_docs_by_parts`, `async_gen_doc_parts`) run under a semaphore and update progress via a callback.  
- `gen_doc_parts`/`async_gen_doc_parts` orchestrate chunk processing, concatenate results, and keep a trailing context slice (≈ 3000 chars).  

**Data flow** – `full_code_mix → split_data → [chunks] → per‑chunk prompt → model → documentation string → aggregated output (side‑effect: logs & progress updates).
[2026-01-26 17:25:50.456534] [INFO] Generating documentation for a part...
[2026-01-26 17:25:50.456563] [INFO] Generating answer...
[2026-01-26 17:26:12.193837] [INFO] Generated answer with model openai/gpt-oss-120b.
[2026-01-26 17:26:12.193903] [INFO] Answer: <a name="logging-classes"></a>  
## Logging classes hierarchy  

`BaseLog` stores a raw message and a numeric *level*. Sub‑classes (`ErrorLog`, `WarningLog`, `InfoLog`) override `format()` to prepend a timestamp (`_log_prefix`) and a severity tag.  

<a name="logger-template-dispatch"></a>  
## Logger template dispatch  

`BaseLoggerTemplate` holds a *log_level* threshold and implements `global_log()`, which forwards a `BaseLog` to `log()` only when the log’s level satisfies the threshold.  

`FileLoggerTemplate` extends the template, overriding `log()` to append formatted entries to a file path supplied at construction.  

`BaseLogger` is a **singleton** façade exposing `set_logger()` to inject any `BaseLoggerTemplate` and a `log()` method that delegates to the injected template’s `global_log()`.  

<a name="progress-implementations"></a>  
## Progress implementations  

`BaseProgress` defines the public API (`create_new_subtask`, `update_task`, `remove_subtask`).  

`LibProgress` wraps *rich.progress.Progress*: it creates a base task, optionally a sub‑task, and advances the appropriate one on `update_task()`.  

`ConsoleGtiHubProgress` provides a lightweight fallback using `ConsoleTask`, which prints simple “Starting task” and incremental percent messages to stdout.  

<a name="data‑flow‑logging‑progress"></a>  
## Data flow & side effects  

- **Logging**: `BaseLogger.log(log_obj)` → `BaseLoggerTemplate.global_log()` → (if level permitted) → `BaseLoggerTemplate.log()`.  
  - *FileLoggerTemplate*: writes a line to the configured file (side‑effect).  
  - *Console* (default `BaseLoggerTemplate`): prints to stdout.  

- **Progress**: client code calls `create_new_subtask(name, total)` → stores task identifier. Subsequent `update_task()` advances either the sub‑task or the base task; `remove_subtask()` clears the sub‑task reference.  

Both subsystems are interchangeable; the UI layer injects the desired logger or progress implementation, enabling unified progress reporting and diagnostic output throughout the documentation generation pipeline.
[2026-01-26 17:26:12.193950] [INFO] Documentation for part generated. total length: 2079
[2026-01-26 17:26:12.193975] [INFO] Part Documentation: <a name="logging-classes"></a>  
## Logging classes hierarchy  

`BaseLog` stores a raw message and a numeric *level*. Sub‑classes (`ErrorLog`, `WarningLog`, `InfoLog`) override `format()` to prepend a timestamp (`_log_prefix`) and a severity tag.  

<a name="logger-template-dispatch"></a>  
## Logger template dispatch  

`BaseLoggerTemplate` holds a *log_level* threshold and implements `global_log()`, which forwards a `BaseLog` to `log()` only when the log’s level satisfies the threshold.  

`FileLoggerTemplate` extends the template, overriding `log()` to append formatted entries to a file path supplied at construction.  

`BaseLogger` is a **singleton** façade exposing `set_logger()` to inject any `BaseLoggerTemplate` and a `log()` method that delegates to the injected template’s `global_log()`.  

<a name="progress-implementations"></a>  
## Progress implementations  

`BaseProgress` defines the public API (`create_new_subtask`, `update_task`, `remove_subtask`).  

`LibProgress` wraps *rich.progress.Progress*: it creates a base task, optionally a sub‑task, and advances the appropriate one on `update_task()`.  

`ConsoleGtiHubProgress` provides a lightweight fallback using `ConsoleTask`, which prints simple “Starting task” and incremental percent messages to stdout.  

<a name="data‑flow‑logging‑progress"></a>  
## Data flow & side effects  

- **Logging**: `BaseLogger.log(log_obj)` → `BaseLoggerTemplate.global_log()` → (if level permitted) → `BaseLoggerTemplate.log()`.  
  - *FileLoggerTemplate*: writes a line to the configured file (side‑effect).  
  - *Console* (default `BaseLoggerTemplate`): prints to stdout.  

- **Progress**: client code calls `create_new_subtask(name, total)` → stores task identifier. Subsequent `update_task()` advances either the sub‑task or the base task; `remove_subtask()` clears the sub‑task reference.  

Both subsystems are interchangeable; the UI layer injects the desired logger or progress implementation, enabling unified progress reporting and diagnostic output throughout the documentation generation pipeline.
[2026-01-26 17:26:12.194068] [INFO] Documentation generation by parts completed.

                       Total documentation length: 15508
[2026-01-26 17:26:12.194108] [INFO] Documentation: <a name="configuration-loading"></a>
## Configuration Loading & Factory Preparation  
`read_config` parses **autodocconfig.yml**, builds a `Config` object, and populates: language, ignore patterns, `ProjectConfigSettings`, additional info, and a list of `CustomModule` instances. It then returns two factories – a generic `doc_factory` (custom modules) and an `intro_factory` (static intro components).

<a name="model-initialization"></a>
## GPT Model Instantiation  
```python
sync_model = GPTModel(API_KEY, use_random=False)
async_model = AsyncGPTModel(API_KEY)
```  
Both models receive the API key from `engine.config`. The synchronous model is used for deterministic calls, while the async variant is prepared for future parallelism.

<a name="manager-orchestration"></a>
## Manager Orchestration & Generation Steps  
A `Manager` is created with the project root, `ProjectSettings`, `ProjectConfigSettings`, the ignore list, and a `ConsoleGtiHubProgress` bar. The subsequent calls execute the full pipeline:  

1. `generate_code_file()` – extracts source files.  
2. `generate_global_info_file(use_async=False, max_symbols=8000)` – builds a project‑wide summary.  
3. `generete_doc_parts(use_async=False, max_symbols=10000)` – splits code into doc‑ready chunks.  
4. `factory_generate_doc(doc_factory)` – runs user‑defined modules.  
5. `order_doc()` – sorts sections.  
6. `factory_generate_doc(intro_factory)` – prepends introductory material.  

Finally, `clear_cache()` removes temporary artifacts and `read_file_by_file_key("output_doc")` returns the rendered Markdown.

<a name="execution-flow"></a>
## Script Execution Flow  
When invoked as a module, the script reads *autodocconfig.yml*, resolves factories, calls `gen_doc` with the assembled parameters, and stores the result in `output_doc`. All side effects (file generation, cache cleanup, progress rendering) are confined to the `Manager` instance.

<a name="model-generation-responsibility"></a>
## Model Generation Responsibility
Implements concrete `GPTModel` (sync) and `AsyncGPTModel` (async) subclasses of the engine’s abstract `Model`/`AsyncModel`. Each class wraps a Groq client, selects a viable model from `regen_models_name`, and returns the generated text while logging progress.

<a name="model-interactions"></a>
## Interaction with Engine & UI
- Inherits shared state (`api_key`, `history`, `use_random`, `regen_models_name`, `current_model_index`) from the base classes.  
- Uses `BaseLogger` from `ui.logging` to emit `InfoLog`, `WarningLog`, and `ErrorLog`.  
- Raises `ModelExhaustedException` when no model remains usable, propagating the error to the surrounding `Manager` workflow.

<a name="model-technical-details"></a>
## Technical Details
- **`__init__`**: Instantiates `Groq` or `AsyncGroq` client with the supplied API key; sets up a logger.  
- **`generate_answer` / `async generate_answer`**:  
  1. Determines message payload (`history.history` vs. direct `prompt`).  
  2. Enters a loop selecting `model_name` from `regen_models_name`.  
  3. Calls `client.chat.completions.create`.  
  4. On exception, logs a warning and advances `current_model_index` (wrap‑around).  
  5. Upon success, extracts `content` from `chat_completion.choices[0].message`.  
  6. Logs the chosen model and final answer before returning it.

<a name="model-data-flow"></a>
## Data Flow & Side Effects
- **Inputs**: `api_key`, optional `history` object, `use_random` flag, `with_history` boolean, optional `prompt` string.  
- **Outputs**: Generated answer string.  
- **Side Effects**: Logging activity, possible modification of `current_model_index`, and raising `ModelExhaustedException` when the model pool is empty.  
- **Assumptions**: `regen_models_name` is pre‑populated with viable model identifiers; `History` provides a `history` list compatible with Groq’s chat API.

<a name="history-management"></a>
## History Management  

The `History` class records conversation turns for chat‑style LLM calls.  
- **Constructor** (`__init__(system_prompt)`) creates an empty `history` list and, if a system prompt is supplied, inserts a `"system"` role entry.  
- **add_to_history(role, content)** appends a dict `{"role": role, "content": content}` to `self.history`.  
*Assumption*: callers provide plain strings; the list format matches Groq/Chat‑ML expectations.

<a name="parentmodel-initialization"></a>
## ParentModel Initialization  

`ParentModel` supplies shared state for both sync and async models.  
- Accepts `api_key` (default from config), a `History` instance, and `use_random`.  
- Stores `self.history`, `self.api_key`, and starts `self.current_model_index = 0`.  
- Copies `MODELS_NAME`, shuffles it when `use_random=True`, and exposes the ordered list as `self.regen_models_name`.  
*Side effect*: randomisation of model selection order for subsequent calls to `generate_answer`.

<a name="synchronous-model-interface"></a>
## Synchronous Model Interface  

`Model` inherits from `ParentModel` and implements three thin wrappers around `generate_answer`.  
- `generate_answer(with_history=True, prompt=None) -> str` – placeholder returning `"answer"` (real implementation is injected elsewhere).  
- `get_answer_without_history(prompt)` forwards to `generate_answer(with_history=False, ...)`.  
- `get_answer(prompt)` records the user prompt, calls `generate_answer()`, stores the assistant reply, and returns the answer.  
*Data flow*: `prompt` → history → `generate_answer` → answer → history.

<a name="asynchronous-model-interface"></a>
## Asynchronous Model Interface  

`AsyncModel` mirrors `Model` but with `async` methods.  
- `async generate_answer(with_history=True, prompt=None) -> str` – stub returning `"answer"`.  
- `async get_answer_without_history(prompt)` awaits `generate_answer`.  
- `async get_answer(prompt)` updates history synchronously, then awaits `generate_answer` before storing and returning the result.  

Both interfaces rely on the shared `History` instance and respect the ordered `regen_models_name` list for model selection in the real `generate_answer` implementation.

<a name="html-link-extractor"></a>
## HTML Link Extractor  

**Responsibility** – Scans a documentation string for `<a name="…"></a>` anchors and returns a list of Markdown‑style fragment links (`#anchor`).  

**Interactions** – Called by the post‑processing pipeline to build a navigation index; relies only on Python’s `re` module and the internal `BaseLogger`.  

**Technical details** –  
- Compiles a simple regex `r'<a name=["\']?(.*?)["\']?>'`.  
- Iterates `re.finditer`, extracts the captured group, prefixes with `#`, logs progress and result.  

**Data flow** – Input: raw HTML/markdown `data : str` → regex search → `links : list[str]` → returned to caller; side effect: logger writes two `InfoLog` entries.

---

<a name="link-introduction-generator"></a>
## Link Introduction Generator  

**Responsibility** – Generates a natural‑language intro that references a set of extracted links.  

**Interactions** – Uses a `Model` implementation (e.g., `GPTModel`) to call `model.get_answer_without_history`. The prompt combines a language directive, a constant `BASE_INTRODACTION_CREATE_TEXT`, and the stringified link list.  

**Technical details** –  
- Builds a 3‑message system/user prompt.  
- Logs before/after the LLM call.  
- Returns the LLM‑produced `intro_links : str`.  

**Data flow** – `links → prompt → model.get_answer_without_history → intro_links`; side effect: three log entries.

---

<a name="global-introduction-generator"></a>
## Global Introduction Generator  

**Responsibility** – Produces a full introductory paragraph for the whole documentation block.  

**Interactions** – Similar to the link generator but uses `BASE_INTRO_CREATE` as the system prompt and passes the complete `global_data`.  

**Technical details** – Constructs a 3‑message prompt and returns the model’s answer unchanged.  

**Data flow** – `global_data → prompt → model.get_answer_without_history → intro`.

---

<a name="custom-description-engine"></a>
## Custom Description Engine  

**Responsibility** – Iterates over split documentation chunks, asking the LLM to create concise, anchor‑prefixed descriptions for a user‑supplied `custom_description`.  

**Interactions** – For each chunk it sends a detailed system prompt (language, role, strict rules) plus a user task to the same `Model`. Stops on the first non‑empty, non‑`!noinfo` result.  

**Technical details** –  
- Loops over `splited_data`.  
- Uses strict rule block to enforce empty output when info is missing.  
- Breaks when a valid result appears; otherwise returns an empty string.  

**Data flow** – `splited_data + custom_description → per‑chunk prompt → model.get_answer_without_history → result`.

---

<a name="anchor-based-chunk-splitter"></a>
## Anchor‑Based Chunk Splitter & Sorter  

**Responsibility** – Parses a monolithic HTML/markdown document into anchor‑delimited chunks, validates one‑to‑one anchor‑chunk mapping, and orders chunks semantically via LLM.  

**Interactions** – `extract_links_from_start` and `split_text_by_anchors` produce a dict `{anchor: chunk}`. `get_order` sends the list of titles to the `Model` for sorting, then reassembles the ordered text.  

**Technical details** –  
- Regex `^<a name=…>` extracts leading anchors.  
- `re.split` with look‑ahead splits on anchor boundaries.  
- Validation: `len(all_links) == len(chunks)` else `None`.  
- Prompt for sorting: single‑message user request, expects comma‑separated titles.  
- Reassembles via `order_output += f"{chanks.get(el)} \n"`.  

**Data flow** – `text → split_text_by_anchors → dict` → `get_order(dict) → sorted string`; logs each step.

---

<a name="repository-content-packager"></a>
## Repository Content Packager  

**Responsibility** – Traverses a project directory, writes a hierarchical tree view and in‑line file contents to a single output file (`repomix-output.txt`).  

**Interactions** – Uses `Path.rglob` to enumerate files, `should_ignore` to filter based on `ignore_patterns`, and `BaseLogger` for progress logs. No external services.  

**Technical details** –  
- `should_ignore` matches against glob patterns, file basenames, and any path component.  
- `build_repo_content` writes a “Repository Structure” block, then each non‑ignored file wrapped in `<file path="…">` tags.  
- Handles read errors with a catch‑all exception, inserting an error line.  

**Data flow** – `root_dir + ignore_patterns → file enumeration → filtered list → output file` (side effect: file creation + log entries).

<a name="compression-engine"></a>
## Compression Engine  

**Responsibility** – Reduces raw text (code or docs) to a concise form using the LLM, optionally grouping several inputs into a single compressed block for later comparison.  

**Interactions** – Calls `project_settings.prompt` and `get_BASE_COMPRESS_TEXT` to build a three‑message prompt, then invokes `model.get_answer_without_history`.  Progress is reported via a `BaseProgress` instance.  

**Technical details** –  
- `compress` builds the prompt (`system` → project prompt, `system` → compress‑text template, `user` → data).  
- `compress_and_compare` iterates over a list, concatenating every *compress_power* results; updates the progress bar.  
- Async counterparts (`async_compress`, `async_compress_and_compare`) run under a semaphore and use `await model.get_answer_without_history`.  

**Data flow** – `data (+ settings) → prompt → model → compressed string`; aggregated list → progress bar side‑effects.

<a name="project-settings-builder"></a>
## Project Settings Builder  

**Responsibility** – Generates a dynamic system prompt containing base settings and project‑specific key/value pairs.  

**Interactions** – Consumed by the compressor and splitter when they need a contextual system message.  

**Technical details** –  
- `ProjectSettings` stores `project_name` and an `info` dict.  
- `add_info(key, value)` mutates the dict.  
- The `prompt` property concatenates `BASE_SETTINGS_PROMPT`, the project name, and each `info` entry on separate lines.  

**Data flow** – `ProjectSettings` instance → `prompt` string → injected into LLM prompts.

<a name="chunk-splitter-and-doc-generator"></a>
## Chunk Splitter & Documentation Generator  

**Responsibility** – Splits a large monolithic source string into size‑constrained chunks, then drives LLM‑based documentation generation per chunk (sync or async).  

**Interactions** – Uses `BASE_PART_COMPLITE_TEXT` as a system prompt, optionally carries forward previous part output (`prev_info`).  Logs via `BaseLogger` and reports progress with `BaseProgress`.  

**Technical details** –  
- `split_data` respects `max_symbols`, recursively breaks overly long lines, and packs them into a list of chunks.  
- `write_docs_by_parts` builds a prompt (system language/id, system base text, optional previous info, user chunk) and cleans surrounding markdown fences.  
- Async versions (`async_write_docs_by_parts`, `async_gen_doc_parts`) run under a semaphore and update progress via a callback.  
- `gen_doc_parts`/`async_gen_doc_parts` orchestrate chunk processing, concatenate results, and keep a trailing context slice (≈ 3000 chars).  

**Data flow** – `full_code_mix → split_data → [chunks] → per‑chunk prompt → model → documentation string → aggregated output (side‑effect: logs & progress updates).

<a name="logging-classes"></a>  
## Logging classes hierarchy  

`BaseLog` stores a raw message and a numeric *level*. Sub‑classes (`ErrorLog`, `WarningLog`, `InfoLog`) override `format()` to prepend a timestamp (`_log_prefix`) and a severity tag.  

<a name="logger-template-dispatch"></a>  
## Logger template dispatch  

`BaseLoggerTemplate` holds a *log_level* threshold and implements `global_log()`, which forwards a `BaseLog` to `log()` only when the log’s level satisfies the threshold.  

`FileLoggerTemplate` extends the template, overriding `log()` to append formatted entries to a file path supplied at construction.  

`BaseLogger` is a **singleton** façade exposing `set_logger()` to inject any `BaseLoggerTemplate` and a `log()` method that delegates to the injected template’s `global_log()`.  

<a name="progress-implementations"></a>  
## Progress implementations  

`BaseProgress` defines the public API (`create_new_subtask`, `update_task`, `remove_subtask`).  

`LibProgress` wraps *rich.progress.Progress*: it creates a base task, optionally a sub‑task, and advances the appropriate one on `update_task()`.  

`ConsoleGtiHubProgress` provides a lightweight fallback using `ConsoleTask`, which prints simple “Starting task” and incremental percent messages to stdout.  

<a name="data‑flow‑logging‑progress"></a>  
## Data flow & side effects  

- **Logging**: `BaseLogger.log(log_obj)` → `BaseLoggerTemplate.global_log()` → (if level permitted) → `BaseLoggerTemplate.log()`.  
  - *FileLoggerTemplate*: writes a line to the configured file (side‑effect).  
  - *Console* (default `BaseLoggerTemplate`): prints to stdout.  

- **Progress**: client code calls `create_new_subtask(name, total)` → stores task identifier. Subsequent `update_task()` advances either the sub‑task or the base task; `remove_subtask()` clears the sub‑task reference.  

Both subsystems are interchangeable; the UI layer injects the desired logger or progress implementation, enabling unified progress reporting and diagnostic output throughout the documentation generation pipeline.


[2026-01-26 17:26:12.194230] [INFO] Documentation generation by parts completed.
[2026-01-26 17:26:12.195081] [INFO] Starting factory documentation generation 

                                CustomModule CustomModule CustomModule 

                                Input params: language: 2 chars global_data: 2 chars full_data: 15508 chars code_mix: 242863 chars
                                
[2026-01-26 17:26:12.195437] [INFO] Starting data splitting...
[2026-01-26 17:26:12.195515] [INFO] Data split into 9 parts based on max symbols 7000.
[2026-01-26 17:26:12.195549] [INFO] Generating answer...
[2026-01-26 17:26:30.228456] [INFO] Generated answer with model openai/gpt-oss-120b.
[2026-01-26 17:26:30.228523] [INFO] Answer: <a href="autodocconfig.yml"></a>To install the workflow, run the appropriate script for your platform:

- **Windows (PowerShell)**:  
  ```powershell
  irm https://raw.githubusercontent.com/Drag-GameStudio/ADG/main/install.ps1 | iex
  ```

- **Linux/macOS (bash)**:  
  ```bash
  curl -sSL https://raw.githubusercontent.com/Drag-GameStudio/ADG/main/install.sh | bash
  ```

Additionally, add a secret variable named **GROCK_API_KEY** to your GitHub Actions settings. Set its value to your API key obtained from the Grock documentation at https://grockdocs.com. This secret is required for the documentation generation workflow to function correctly.
[2026-01-26 17:26:30.228570] [INFO] Module CustomModule generated its part of the documentation.
[2026-01-26 17:26:30.228596] [INFO] Module Output: <a href="autodocconfig.yml"></a>To install the workflow, run the appropriate script for your platform:

- **Windows (PowerShell)**:  
  ```powershell
  irm https://raw.githubusercontent.com/Drag-GameStudio/ADG/main/install.ps1 | iex
  ```

- **Linux/macOS (bash)**:  
  ```bash
  curl -sSL https://raw.githubusercontent.com/Drag-GameStudio/ADG/main/install.sh | bash
  ```

Additionally, add a secret variable named **GROCK_API_KEY** to your GitHub Actions settings. Set its value to your API key obtained from the Grock documentation at https://grockdocs.com. This secret is required for the documentation generation workflow to function correctly.
[2026-01-26 17:26:30.228998] [INFO] Starting data splitting...
[2026-01-26 17:26:30.229096] [INFO] Data split into 9 parts based on max symbols 7000.
[2026-01-26 17:26:30.229133] [INFO] Generating answer...
[2026-01-26 17:26:47.904675] [INFO] Generated answer with model openai/gpt-oss-120b.
[2026-01-26 17:26:47.904740] [INFO] Answer: <a href="autodocgenerator/manage.py"></a>!noinfo
[2026-01-26 17:26:47.904782] [INFO] Module CustomModule generated its part of the documentation.
[2026-01-26 17:26:47.904807] [INFO] Module Output: <a href="autodocgenerator/manage.py"></a>!noinfo
[2026-01-26 17:26:47.905201] [INFO] Starting data splitting...
[2026-01-26 17:26:47.905293] [INFO] Data split into 9 parts based on max symbols 7000.
[2026-01-26 17:26:47.905328] [INFO] Generating answer...
[2026-01-26 17:27:07.296002] [INFO] Generated answer with model openai/gpt-oss-120b.
[2026-01-26 17:27:07.296087] [INFO] Answer: <a href="autodocconfig.yml"></a>
The `autodocconfig.yml` file is a YAML document that defines the settings for the Auto Doc Generator. The available top‑level options are:

* **project_name** – a string with the name of the project.  
  Example: `project_name: "Auto Doc Generator"`

* **language** – the language code used for the generated documentation (e.g., `en`).  

* **project_settings** – a mapping that controls generator behaviour:  
  * **save_logs** – boolean, whether to write logs to files.  
  * **log_level** – integer, the verbosity level of logging.

* **project_additional_info** – a free‑form mapping for any extra information you want to attach to the project. Each entry is a key/value pair (both strings).  
  Example:  
  ```yaml
  project_additional_info:
    global idea: "This project was created to help developers make documentations for them projects"
  ```

* **custom_descriptions** – a list of strings. Each string is a custom description that will be turned into a documentation module.  
  Example:  
  ```yaml
  custom_descriptions:
    - "explain how install workflow with install.ps1 and install.sh scripts …"
    - "how to use Manager class what parameters i need to give. give full example of usage"
    - "explain how to write autodocconfig.yml file what options are available"
  ```

When writing the file, keep the YAML indentation consistent and include only the keys you need; omitted keys will use the defaults defined in the code.
[2026-01-26 17:27:07.296138] [INFO] Module CustomModule generated its part of the documentation.
[2026-01-26 17:27:07.296164] [INFO] Module Output: <a href="autodocconfig.yml"></a>
The `autodocconfig.yml` file is a YAML document that defines the settings for the Auto Doc Generator. The available top‑level options are:

* **project_name** – a string with the name of the project.  
  Example: `project_name: "Auto Doc Generator"`

* **language** – the language code used for the generated documentation (e.g., `en`).  

* **project_settings** – a mapping that controls generator behaviour:  
  * **save_logs** – boolean, whether to write logs to files.  
  * **log_level** – integer, the verbosity level of logging.

* **project_additional_info** – a free‑form mapping for any extra information you want to attach to the project. Each entry is a key/value pair (both strings).  
  Example:  
  ```yaml
  project_additional_info:
    global idea: "This project was created to help developers make documentations for them projects"
  ```

* **custom_descriptions** – a list of strings. Each string is a custom description that will be turned into a documentation module.  
  Example:  
  ```yaml
  custom_descriptions:
    - "explain how install workflow with install.ps1 and install.sh scripts …"
    - "how to use Manager class what parameters i need to give. give full example of usage"
    - "explain how to write autodocconfig.yml file what options are available"
  ```

When writing the file, keep the YAML indentation consistent and include only the keys you need; omitted keys will use the defaults defined in the code.
[2026-01-26 17:27:07.296247] [INFO] Factory documentation generation completed.
[2026-01-26 17:27:07.297374] [INFO] Starting factory documentation generation 

                                IntroLinks 

                                Input params: language: 2 chars global_data: 2 chars full_data: 17692 chars code_mix: 242863 chars
                                
[2026-01-26 17:27:07.297446] [INFO] Extracting HTML links from documentation...
[2026-01-26 17:27:07.297662] [INFO] Extracted 26 HTML links from documentation.
[2026-01-26 17:27:07.297706] [INFO] Links: ['#configuration-loading', '#model-initialization', '#manager-orchestration', '#execution-flow', '#model-generation-responsibility', '#model-interactions', '#model-technical-details', '#model-data-flow', '#history-management', '#parentmodel-initialization', '#synchronous-model-interface', '#asynchronous-model-interface', '#html-link-extractor', '#…', '#link-introduction-generator', '#global-introduction-generator', '#custom-description-engine', '#anchor-based-chunk-splitter', '#repository-content-packager', '#compression-engine', '#project-settings-builder', '#chunk-splitter-and-doc-generator', '#logging-classes', '#logger-template-dispatch', '#progress-implementations', '#data‑flow‑logging‑progress']
[2026-01-26 17:27:07.297747] [INFO] Generating introduction with links...
[2026-01-26 17:27:07.297770] [INFO] Generating answer...
[2026-01-26 17:27:11.170563] [INFO] Generated answer with model openai/gpt-oss-120b.
[2026-01-26 17:27:11.170621] [INFO] Answer: ## Executive Navigation Tree
- 📂 Configuration
  - [#configuration-loading](#configuration-loading)

- 📂 Model Management
  - [#model-initialization](#model-initialization)
  - [#manager-orchestration](#manager-orchestration)
  - [#model-generation-responsibility](#model-generation-responsibility)
  - [#model-interactions](#model-interactions)
  - [#model-technical-details](#model-technical-details)
  - [#model-data-flow](#model-data-flow)
  - [#parentmodel-initialization](#parentmodel-initialization)

- ⚙️ Execution
  - [#execution-flow](#execution-flow)

- 📜 History
  - [#history-management](#history-management)

- 🔌 Interface
  - [#synchronous-model-interface](#synchronous-model-interface)
  - [#asynchronous-model-interface](#asynchronous-model-interface)

- 🛠️ Utilities
  - [#html-link-extractor](#html-link-extractor)

- ❓ Misc
  - [#…](#…)

- 🚀 Generators
  - [#link-introduction-generator](#link-introduction-generator)
  - [#global-introduction-generator](#global-introduction-generator)

- 🧠 Engines
  - [#custom-description-engine](#custom-description-engine)
  - [#compression-engine](#compression-engine)

- 📦 Chunking
  - [#anchor-based-chunk-splitter](#anchor-based-chunk-splitter)
  - [#chunk-splitter-and-doc-generator](#chunk-splitter-and-doc-generator)

- 📦 Packaging
  - [#repository-content-packager](#repository-content-packager)

- 🛠️ Settings
  - [#project-settings-builder](#project-settings-builder)

- 📓 Logging
  - [#logging-classes](#logging-classes)
  - [#logger-template-dispatch](#logger-template-dispatch)

- 📈 Progress
  - [#progress-implementations](#progress-implementations)
  - [#data‑flow‑logging‑progress](#data‑flow‑logging‑progress)
[2026-01-26 17:27:11.170655] [INFO] Introduction with links generated.
[2026-01-26 17:27:11.170678] [INFO] Introduction Links: ## Executive Navigation Tree
- 📂 Configuration
  - [#configuration-loading](#configuration-loading)

- 📂 Model Management
  - [#model-initialization](#model-initialization)
  - [#manager-orchestration](#manager-orchestration)
  - [#model-generation-responsibility](#model-generation-responsibility)
  - [#model-interactions](#model-interactions)
  - [#model-technical-details](#model-technical-details)
  - [#model-data-flow](#model-data-flow)
  - [#parentmodel-initialization](#parentmodel-initialization)

- ⚙️ Execution
  - [#execution-flow](#execution-flow)

- 📜 History
  - [#history-management](#history-management)

- 🔌 Interface
  - [#synchronous-model-interface](#synchronous-model-interface)
  - [#asynchronous-model-interface](#asynchronous-model-interface)

- 🛠️ Utilities
  - [#html-link-extractor](#html-link-extractor)

- ❓ Misc
  - [#…](#…)

- 🚀 Generators
  - [#link-introduction-generator](#link-introduction-generator)
  - [#global-introduction-generator](#global-introduction-generator)

- 🧠 Engines
  - [#custom-description-engine](#custom-description-engine)
  - [#compression-engine](#compression-engine)

- 📦 Chunking
  - [#anchor-based-chunk-splitter](#anchor-based-chunk-splitter)
  - [#chunk-splitter-and-doc-generator](#chunk-splitter-and-doc-generator)

- 📦 Packaging
  - [#repository-content-packager](#repository-content-packager)

- 🛠️ Settings
  - [#project-settings-builder](#project-settings-builder)

- 📓 Logging
  - [#logging-classes](#logging-classes)
  - [#logger-template-dispatch](#logger-template-dispatch)

- 📈 Progress
  - [#progress-implementations](#progress-implementations)
  - [#data‑flow‑logging‑progress](#data‑flow‑logging‑progress)
[2026-01-26 17:27:11.170724] [INFO] Module IntroLinks generated its part of the documentation.
[2026-01-26 17:27:11.170746] [INFO] Module Output: ## Executive Navigation Tree
- 📂 Configuration
  - [#configuration-loading](#configuration-loading)

- 📂 Model Management
  - [#model-initialization](#model-initialization)
  - [#manager-orchestration](#manager-orchestration)
  - [#model-generation-responsibility](#model-generation-responsibility)
  - [#model-interactions](#model-interactions)
  - [#model-technical-details](#model-technical-details)
  - [#model-data-flow](#model-data-flow)
  - [#parentmodel-initialization](#parentmodel-initialization)

- ⚙️ Execution
  - [#execution-flow](#execution-flow)

- 📜 History
  - [#history-management](#history-management)

- 🔌 Interface
  - [#synchronous-model-interface](#synchronous-model-interface)
  - [#asynchronous-model-interface](#asynchronous-model-interface)

- 🛠️ Utilities
  - [#html-link-extractor](#html-link-extractor)

- ❓ Misc
  - [#…](#…)

- 🚀 Generators
  - [#link-introduction-generator](#link-introduction-generator)
  - [#global-introduction-generator](#global-introduction-generator)

- 🧠 Engines
  - [#custom-description-engine](#custom-description-engine)
  - [#compression-engine](#compression-engine)

- 📦 Chunking
  - [#anchor-based-chunk-splitter](#anchor-based-chunk-splitter)
  - [#chunk-splitter-and-doc-generator](#chunk-splitter-and-doc-generator)

- 📦 Packaging
  - [#repository-content-packager](#repository-content-packager)

- 🛠️ Settings
  - [#project-settings-builder](#project-settings-builder)

- 📓 Logging
  - [#logging-classes](#logging-classes)
  - [#logger-template-dispatch](#logger-template-dispatch)

- 📈 Progress
  - [#progress-implementations](#progress-implementations)
  - [#data‑flow‑logging‑progress](#data‑flow‑logging‑progress)
[2026-01-26 17:27:11.170815] [INFO] Factory documentation generation completed.
